{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposures and Centroids (using pandas and cartopy)\n",
    "\n",
    "Prepared by G. Aznar Siguan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercises we will work with the `Exposures` and `Centroids` classes of climada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exposures class\n",
    "\n",
    "Looking at the documentation, in the `Attributes` section, we see that this class contains the following attributes:\n",
    "\n",
    " * tag (Tag): information about the source data\n",
    " * ref_year (int): reference year\n",
    " * value_unit (str): unit of the exposures values\n",
    " * id (np.array): an id for each exposure\n",
    " * coord (np.array or Coordinates): 2d array with lat in first column and lon in second, or Coordinates instance. \"lat\" and \"lon\" are descriptors of the latitude and longitude respectively.\n",
    " * value (np.array): a value for each exposure\n",
    " * impact_id (np.array): impact function id corresponding to each exposure\n",
    " * deductible (np.array, default): deductible value for each exposure\n",
    " * cover (np.array, default): cover value for each exposure\n",
    " * category_id (np.array, optional): category id for each exposure (when defined)\n",
    " * region_id (np.array, optional): region id for each exposure (when defined)\n",
    " * assigned (dict, optional): for a given hazard, id of the centroid(s) affecting each exposure. Filled in 'assign' method.\n",
    "\n",
    "Some of the variables are *optional*. This means that climada also works without these variables. For instance, the `region_id` and `category_id` values only provide additional information. The `assigned` variable can be computed if not provided.\n",
    "\n",
    "Other variables are *default*. These are the ones that receive default values if not provided. The default values are assigned in the `check()` method, and this is automatically called when reading a file. `cover` receives the value of the exposure as default, whilst `deductible` receives zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.entity import Exposures\n",
    "\n",
    "help(Exposures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start importing the name of the Excel file we will use, which is stored in the variable `ENT_TEST_XLS`. You might have a look to this file, which is in the path shown next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from climada.util import SOURCE_DIR\n",
    "ENT_TEST_XLS = os.path.join(SOURCE_DIR, 'entity/test/data', 'demo_today.xlsx')\n",
    "print(ENT_TEST_XLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally climada uses Pandas DataFrames to retrieve the excel data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short explanation on pandas `DataFrame` capabilities. \n",
    "\n",
    "A dataframe is obtained when reading an excel file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# the sheet which contains the exposures data is assets\n",
    "dfr = pd.read_excel(ENT_TEST_XLS, 'assets') # Dataframe\n",
    "dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting columns and row: \n",
    "\n",
    "To select one column, index the name of the column. To get the rows, use the indixing as in numpy arrays. If you want to get multiple columns, use a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Latitude \\n', dfr[:10]['Latitude'])\n",
    "print()\n",
    "print('Latitude and Longitude \\n',dfr[:10][['Latitude', 'Longitude']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the type of the returned column is a `Series` and pandas Series are internally numpy arrays. \n",
    "Adding `.values` to the end of the `Series` you get the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Column type:', type(dfr[:10]['Latitude']))\n",
    "print('Internal numpy array:', dfr[:10]['Latitude'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the maximum and minimum latitudes and longitudes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min lat lon: \\n', dfr[['Latitude', 'Longitude']].min())\n",
    "print()\n",
    "print('Max lat lon: \\n', dfr[['Latitude', 'Longitude']].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are the damage functions (DamageFunID) used? Use `value_counts()` to answer this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr['DamageFunID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logical indexing can be also performed. \n",
    "\n",
    "Example: Return the exposures that satisfy both conditions:\n",
    "- latitude in [26.5, max(Latitude) - 0.1] \n",
    "- longitude in [min(Longitude) + 0.1, -80.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latitudes in range\n",
    "sel_lat = (dfr['Latitude'] <= dfr['Latitude'].max() - 0.1) & (dfr['Latitude'] >= 26.5)\n",
    "# Longitudes in range\n",
    "sel_lon = (dfr['Longitude'] <= -80.5) & (dfr['Longitude'] >= dfr['Longitude'].min() + 0.1)\n",
    "# Latitude, Longitude and Value of selected exposures\n",
    "dfr[['Latitude', 'Longitude', 'Value']][sel_lat & sel_lon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also has plot functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dfr[['Value']].plot.hist(bins = 3)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('N')\n",
    "plt.title('Value histogram');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On cartopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cartopy enables to add to the plot different earth values in different projections. \n",
    "\n",
    "The instructions `plt.axes(projection=ccrs.PlateCarree())` and `plt.subplot(projection=ccrs.PlateCarree())` set up a `GeoAxes` instance. This is a subclass of `matplotlib.axes.Axes` class that represents a map projection. As such, it exposes a variety of map related methods, as for example the `coastlines()` method to add coast lines to the map.\n",
    "\n",
    "A list of the available projections to be used with matplotlib can be found on the [Cartopy projection list](http://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html#cartopy-projections) page. PlateCarree is the equirectangular projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "plt.figure(figsize=(12, 9))     # set figure size\n",
    "gs = plt.GridSpec(1, 2)         # define subplots\n",
    "ax1 = plt.subplot(gs[0, 0], projection=ccrs.PlateCarree()) # axis with PlateCarree projection\n",
    "ax2 = plt.subplot(gs[0, 1], projection=ccrs.Robinson())    # axis with Robinson projection\n",
    "\n",
    "ax1.coastlines() # add coast lines to first axis\n",
    "ax2.coastlines() # add coast lines to second axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the map just the way you want it, data can be added to it in exactly the same way as with normal matplotlib axes. Here an example with the Exposures data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "# Data\n",
    "dfr = pd.read_excel(ENT_TEST_XLS, 'assets') \n",
    "\n",
    "# Generate axis with equirectangular projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree()) \n",
    "\n",
    "# Set axis labels and values format\n",
    "grid = ax.gridlines(draw_labels=True)\n",
    "grid.xlabels_top = grid.ylabels_right = False\n",
    "grid.xformatter = LONGITUDE_FORMATTER\n",
    "grid.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "# Add coastlines with 10m resolution\n",
    "ax.coastlines(resolution='10m') \n",
    "\n",
    "# 2d histogram plot\n",
    "hex_bin = ax.hexbin(dfr['Longitude'].values, dfr['Latitude'].values, C=dfr['Value'].values, gridsize=15)\n",
    "\n",
    "# set axis limits\n",
    "extent = [dfr['Latitude'].values.min() - 1.5, dfr['Latitude'].values.max() + 1.5, \n",
    "          dfr['Longitude'].values.min() - 1.5, dfr['Longitude'].values.max() + 1.5]\n",
    "ax.set_extent([-82, -79, 25, 27.5], ccrs.PlateCarree())\n",
    "\n",
    "# Create colorbar in this axis\n",
    "cbax = make_axes_locatable(ax).append_axes('right', size=\"6.5%\", pad=0.1, axes_class=plt.Axes)\n",
    "cbar = plt.colorbar(hex_bin, cax=cbax, orientation='vertical')\n",
    "cbar.set_label('USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples here: http://scitools.org.uk/cartopy/docs/v0.15/gallery.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Exposures\n",
    "\n",
    "Just like with the `ImpactFuncSet` class, `Exposures` can be filled at instantiation or with the `read()` method. An info log appears for every optional variable that has not been filled. The default minimum logging level shown is INFO. To modify the logging level or other configuration parameters, generate a `climada.conf` file with the same structure as the default `defaults.conf` file and locate it in the climada folder (see [Configuration options](https://github.com/davidnbresch/climada_python/blob/master/README.md)).\n",
    "\n",
    "Exposures contains a `tag` variable which contains the file name(s) loaded and description(s) of each, if a description is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Exposures(ENT_TEST_XLS) # Without description\n",
    "print('Tag information:')\n",
    "print(exp.tag)\n",
    "print()\n",
    "exp = Exposures(ENT_TEST_XLS, 'Exposures in Florida.') # With description\n",
    "print('Tag information:')\n",
    "print(exp.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the exposures can be visualized using the `plot()` function. This function accepts the `kwargs` arguments of the matplotlib [matplotlib hexbin](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hexbin.html) function, so that different options can be easily set. Moreover, the plot functions return the figure and axes, so that they can be modified afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "1. Get the mean and standard deviation of the exposure values.\n",
    "2. Get the coordinates where the minimum and maximum exposure values are reached. \n",
    "3. Plot the values with the default settings.\n",
    "4. Plot the values with a gridsize of 10 and a colormap (\"cmap\") of your choice: https://matplotlib.org/examples/color/colormaps_reference.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# 1. value variable is an numpy array\n",
    "print('Mean value:', exp.value.mean())\n",
    "print('Mean std:', exp.value.std())\n",
    "\n",
    "# 2. latitude and longitude can be directly accessed (they are properties of the class)\n",
    "print('Coordinates maximum value: (lat, lon) = (', exp.lat[np.argmax(exp.value)],',', exp.lon[np.argmax(exp.value)], ')')\n",
    "print('Coordinates maximum value: (lat, lon) = (', exp.lat[np.argmin(exp.value)],',', exp.lon[np.argmin(exp.value)], ')')\n",
    "\n",
    "# 3.\n",
    "exp.plot() # Default configuration\n",
    "\n",
    "# 4.\n",
    "exp.plot(gridsize=10, cmap='rainbow')  # Decrease number of bins and change colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded the excel file without having to specify which are the names of the variables contained in the file. This is possible, because climada contains default variable names for each file type. \n",
    "\n",
    "To see which are the name of the variables that have been read, you can use the `get_def_file_var_names()` method. Under the value `col_name`, the dictionary contains a key for each `Exposures` variable and a value which is the variable name in the excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_def_file_var_names('.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to import an excel file with other variable names, produces an ERROR message and trace as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.util import DATA_DIR # folder containing all the test and demo data\n",
    "WS_EXP = DATA_DIR + '/demo/WS_Europe.xls'\n",
    "\n",
    "try:\n",
    "    exp_eu = Exposures(WS_EXP)\n",
    "except KeyError:\n",
    "    print('Error caught.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load an excel file with different variable names, we can modify the previous values and provide that dictionary as input to the `read()` function.\n",
    "\n",
    "### EXERCISE\n",
    "\n",
    "Read the `climada/test/data/demo/WS_Europe.xls` exposures data and plot the exposures values. Notice that this file contains the corresponding impact function id under the variable `VulnCurveID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "# 1. Define exposures instance\n",
    "exp_eu = Exposures()\n",
    "\n",
    "# 2. Define new variable names:\n",
    "# Retrieve default variable names\n",
    "var_names = exp_eu.get_def_file_var_names('.xls')\n",
    "# Modify variable name\n",
    "var_names['col_name']['imp'] = 'VulnCurveID'\n",
    "\n",
    "# 3. Read with new variable names:\n",
    "description = 'Europe exposures winter storm'\n",
    "exp_eu.read(WS_EXP, description, var_names)\n",
    "exp_eu.plot() # plot default\n",
    "exp_eu.plot(pop_name=False) # plot without populated places names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Exposures can be appended. Since one geographical coordinate can have several exposures values, repeated coordinates are allowed in the `Exposures` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of exposures in Florida: ', exp.id.size)\n",
    "print('Number of exposures in EU: ', exp_eu.id.size)\n",
    "exp.append(exp_eu)\n",
    "print('Number exposures Florida + EU: ', exp.id.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several files can be also be read jointly providing a list with the file names or the name of a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.util import ENT_DEMO_MAT\n",
    "file_names = [ENT_DEMO_MAT, ENT_TEST_XLS]\n",
    "exp_all = Exposures(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centroids class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Centroids` class contains geographical coordinates. This class is used to define the grid (regular or irregular) where the hazard events are going to be resampled. The attributes are the following:\n",
    "\n",
    "* tag (Tag): information about the source\n",
    "* coord (np.array or Coordinates): 2d array with lat in first column and lon in second, or Coordinates instance. \"lat\" and \"lon\" are descriptors of the latitude and longitude respectively.\n",
    "* id (np.array): an id for each centroid\n",
    "* region_id (np.array, optional): region id for each centroid (when defined)\n",
    "* dist_coast (np.array, optional): distance to coast in km\n",
    "* admin0_name (str, optional): admin0 country name\n",
    "* admin0_iso3 (str, optional): admin0 ISO3 country name\n",
    "\n",
    "The `coord` variable is the one containing the coordinates. Actually, it is an instance of the `GridPoints` class (defined in the `util` package), which offers additional functionalities as checking if a grid is regular or not. `coord` can be simply used a 2d numpy array.\n",
    "\n",
    "Climada classes can read different file formats. To check which ones, execute the function `get_sup_file_format()`. This method can be executed on the class directly, since it's a static mathod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from climada.hazard import Centroids\n",
    "\n",
    "Centroids.get_sup_file_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "Similarly as with the `Exposures` and `ImpactFuncSet` classes, do the following:\n",
    " - read climada's GLB_CENTROIDS_MAT. This file contains a grid of centroids over the whole Earth and is used as default data when no centroids are provided to climada.\n",
    " - plot the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from climada.util import GLB_CENTROIDS_MAT\n",
    "\n",
    "glb_cent = Centroids(GLB_CENTROIDS_MAT)\n",
    "\n",
    "glb_cent.plot() # Plot with default settings\n",
    "\n",
    "fig, ax = glb_cent.plot(s=0.9) # Change marker size\n",
    "ax.set_xlim(-12, 25)      # Zoom Europe\n",
    "ax.set_ylim(36, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When computing the impacts, the values defined at `Exposures` are interpolated to the `Centroids` coordinates. This is done with the `assign()` method of the Exposures. Currently climada supports the nearest neighbor implementation with two different distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the interpolation module contains the interpolation functions\n",
    "from climada.util.interpolation import METHOD, DIST_DEF\n",
    "print('Methods', METHOD)\n",
    "print('Distances', DIST_DEF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `approx` implementation works fast for small amounts of data, whilst `haversine` is faster for large amounts of data. `haversine` is used in most of the cases, as for instance in the `assign()` method.\n",
    "\n",
    "The Earth centroids `GLB_CENTROIDS_MAT` contains 1.656.093 points, and the European entities for winter storms contain 6.187 points. Let's measure how much time it takes to compute the nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Earth centroids GLB_CENTROIDS_MAT contains 1656093 points and\n",
    "# the European entities for winter storms contains 6186 points.\n",
    "import time\n",
    "time0 = time.time()\n",
    "# The results are the closest centroids indexes for each exposure\n",
    "interp_val = glb_cent.coord.resample_nn(exp_eu.coord)\n",
    "timef = time.time()\n",
    "print('The resampling took', timef - time0, 'seconds')\n",
    "print('Result size:', interp_val.size)\n",
    "print('Closest centroid of the first exposure:', glb_cent.lat[interp_val[0]], glb_cent.lon[interp_val[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two `Centroids` instances can be appended as well with the `append()` method. Since there can not be two centroids with the same coordinates, a check is performed to remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "Read, append and plot the following two centroids files: `HAZ_DEMO_MAT` and `BRB_CENT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climada.util import HAZ_DEMO_MAT, SOURCE_DIR\n",
    "BRB_CENT = os.path.join(SOURCE_DIR, 'hazard/centroids/test/data', 'centr_brb_test.mat')\n",
    "\n",
    "# Put your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "from climada.util import HAZ_DEMO_MAT, SOURCE_DIR\n",
    "BRB_CENT = os.path.join(SOURCE_DIR, 'hazard/centroids/test/data', 'centr_brb_test.mat')\n",
    "\n",
    "# Option 1: Read individually and append\n",
    "fl_centr = Centroids(HAZ_DEMO_MAT)\n",
    "brb_centr = Centroids(BRB_CENT)\n",
    "fl_centr.append(brb_centr)\n",
    "fl_centr.plot()\n",
    "\n",
    "# Option 2: Read both together\n",
    "all_centr = Centroids([HAZ_DEMO_MAT, BRB_CENT])\n",
    "all_centr.plot(s=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "From the last generated centroids, get the id of the centroid closest to lat, lon = (13.7, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "print('Closest centroid id:', all_centr.get_nearest_id(13.7, 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
